{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Supervised Learning Model Comparison\n",
    "\n",
    "---\n",
    "\n",
    "### Let us begin...\n",
    "\n",
    "Recall the `data science process`.\n",
    "   1. Define the problem.\n",
    "   2. Gather the data.\n",
    "   3. Explore the data.\n",
    "   4. Model the data.\n",
    "   5. Evaluate the model.\n",
    "   6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. Thus, we'll define the problem and gather the data for you.\n",
    "Most of the questions requiring a written response can be written in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data in order to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that there are certain tax benefits to these accounts. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, check out [this site](https://www.nerdwallet.com/article/ira-vs-401k-retirement-accounts).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "#### NOTE: When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. \n",
    "\n",
    "#### When predicting `e401k`, you may use the entire dataframe if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data.\n",
    "\n",
    "##### 1. Read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingRegressor,RandomForestRegressor,AdaBoostRegressor,BaggingClassifier,RandomForestClassifier, ExtraTreesClassifier,AdaBoostClassifier\n",
    "from sklearn.metrics import mean_squared_error,root_mean_squared_error,accuracy_score,precision_score, recall_score,f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('401ksubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9275 entries, 0 to 9274\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   e401k   9275 non-null   int64  \n",
      " 1   inc     9275 non-null   float64\n",
      " 2   marr    9275 non-null   int64  \n",
      " 3   male    9275 non-null   int64  \n",
      " 4   age     9275 non-null   int64  \n",
      " 5   fsize   9275 non-null   int64  \n",
      " 6   nettfa  9275 non-null   float64\n",
      " 7   p401k   9275 non-null   int64  \n",
      " 8   pira    9275 non-null   int64  \n",
      " 9   incsq   9275 non-null   float64\n",
      " 10  agesq   9275 non-null   int64  \n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 797.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.392129</td>\n",
       "      <td>39.254641</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.204420</td>\n",
       "      <td>41.080216</td>\n",
       "      <td>2.885067</td>\n",
       "      <td>19.071675</td>\n",
       "      <td>0.276226</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>2121.192483</td>\n",
       "      <td>1793.652722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.488252</td>\n",
       "      <td>24.090002</td>\n",
       "      <td>0.483213</td>\n",
       "      <td>0.403299</td>\n",
       "      <td>10.299517</td>\n",
       "      <td>1.525835</td>\n",
       "      <td>63.963838</td>\n",
       "      <td>0.447154</td>\n",
       "      <td>0.435513</td>\n",
       "      <td>3001.469424</td>\n",
       "      <td>895.648841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-502.302000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.160100</td>\n",
       "      <td>625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>469.155600</td>\n",
       "      <td>1089.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.288000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1108.091000</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.160000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.449500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2516.025500</td>\n",
       "      <td>2304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>199.041000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1536.798000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39617.320000</td>\n",
       "      <td>4096.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             e401k          inc         marr         male          age  \\\n",
       "count  9275.000000  9275.000000  9275.000000  9275.000000  9275.000000   \n",
       "mean      0.392129    39.254641     0.628571     0.204420    41.080216   \n",
       "std       0.488252    24.090002     0.483213     0.403299    10.299517   \n",
       "min       0.000000    10.008000     0.000000     0.000000    25.000000   \n",
       "25%       0.000000    21.660000     0.000000     0.000000    33.000000   \n",
       "50%       0.000000    33.288000     1.000000     0.000000    40.000000   \n",
       "75%       1.000000    50.160000     1.000000     0.000000    48.000000   \n",
       "max       1.000000   199.041000     1.000000     1.000000    64.000000   \n",
       "\n",
       "             fsize       nettfa        p401k         pira         incsq  \\\n",
       "count  9275.000000  9275.000000  9275.000000  9275.000000   9275.000000   \n",
       "mean      2.885067    19.071675     0.276226     0.254340   2121.192483   \n",
       "std       1.525835    63.963838     0.447154     0.435513   3001.469424   \n",
       "min       1.000000  -502.302000     0.000000     0.000000    100.160100   \n",
       "25%       2.000000    -0.500000     0.000000     0.000000    469.155600   \n",
       "50%       3.000000     2.000000     0.000000     0.000000   1108.091000   \n",
       "75%       4.000000    18.449500     1.000000     1.000000   2516.025500   \n",
       "max      13.000000  1536.798000     1.000000     1.000000  39617.320000   \n",
       "\n",
       "             agesq  \n",
       "count  9275.000000  \n",
       "mean   1793.652722  \n",
       "std     895.648841  \n",
       "min     625.000000  \n",
       "25%    1089.000000  \n",
       "50%    1600.000000  \n",
       "75%    2304.000000  \n",
       "max    4096.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e401k     0\n",
       "inc       0\n",
       "marr      0\n",
       "male      0\n",
       "age       0\n",
       "fsize     0\n",
       "nettfa    0\n",
       "p401k     0\n",
       "pira      0\n",
       "incsq     0\n",
       "agesq     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e401k</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.268178</td>\n",
       "      <td>0.080843</td>\n",
       "      <td>-0.027641</td>\n",
       "      <td>0.031526</td>\n",
       "      <td>0.012015</td>\n",
       "      <td>0.143950</td>\n",
       "      <td>0.769170</td>\n",
       "      <td>0.118643</td>\n",
       "      <td>0.206618</td>\n",
       "      <td>0.017526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inc</th>\n",
       "      <td>0.268178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.362008</td>\n",
       "      <td>-0.069871</td>\n",
       "      <td>0.105638</td>\n",
       "      <td>0.110170</td>\n",
       "      <td>0.376586</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.364354</td>\n",
       "      <td>0.940161</td>\n",
       "      <td>0.087305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marr</th>\n",
       "      <td>0.080843</td>\n",
       "      <td>0.362008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.363950</td>\n",
       "      <td>0.059047</td>\n",
       "      <td>0.564814</td>\n",
       "      <td>0.075039</td>\n",
       "      <td>0.085636</td>\n",
       "      <td>0.116925</td>\n",
       "      <td>0.280060</td>\n",
       "      <td>0.054500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>-0.027641</td>\n",
       "      <td>-0.069871</td>\n",
       "      <td>-0.363950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.120297</td>\n",
       "      <td>-0.320678</td>\n",
       "      <td>-0.018132</td>\n",
       "      <td>-0.024949</td>\n",
       "      <td>-0.036361</td>\n",
       "      <td>-0.053715</td>\n",
       "      <td>-0.116235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.031526</td>\n",
       "      <td>0.105638</td>\n",
       "      <td>0.059047</td>\n",
       "      <td>-0.120297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030536</td>\n",
       "      <td>0.203906</td>\n",
       "      <td>0.025977</td>\n",
       "      <td>0.238557</td>\n",
       "      <td>0.097584</td>\n",
       "      <td>0.992619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fsize</th>\n",
       "      <td>0.012015</td>\n",
       "      <td>0.110170</td>\n",
       "      <td>0.564814</td>\n",
       "      <td>-0.320678</td>\n",
       "      <td>-0.030536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031506</td>\n",
       "      <td>0.014296</td>\n",
       "      <td>-0.043629</td>\n",
       "      <td>0.079570</td>\n",
       "      <td>-0.055924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nettfa</th>\n",
       "      <td>0.143950</td>\n",
       "      <td>0.376586</td>\n",
       "      <td>0.075039</td>\n",
       "      <td>-0.018132</td>\n",
       "      <td>0.203906</td>\n",
       "      <td>-0.031506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.187392</td>\n",
       "      <td>0.345917</td>\n",
       "      <td>0.407568</td>\n",
       "      <td>0.203703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p401k</th>\n",
       "      <td>0.769170</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.085636</td>\n",
       "      <td>-0.024949</td>\n",
       "      <td>0.025977</td>\n",
       "      <td>0.014296</td>\n",
       "      <td>0.187392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.153033</td>\n",
       "      <td>0.222113</td>\n",
       "      <td>0.015740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pira</th>\n",
       "      <td>0.118643</td>\n",
       "      <td>0.364354</td>\n",
       "      <td>0.116925</td>\n",
       "      <td>-0.036361</td>\n",
       "      <td>0.238557</td>\n",
       "      <td>-0.043629</td>\n",
       "      <td>0.345917</td>\n",
       "      <td>0.153033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.322805</td>\n",
       "      <td>0.233543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incsq</th>\n",
       "      <td>0.206618</td>\n",
       "      <td>0.940161</td>\n",
       "      <td>0.280060</td>\n",
       "      <td>-0.053715</td>\n",
       "      <td>0.097584</td>\n",
       "      <td>0.079570</td>\n",
       "      <td>0.407568</td>\n",
       "      <td>0.222113</td>\n",
       "      <td>0.322805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agesq</th>\n",
       "      <td>0.017526</td>\n",
       "      <td>0.087305</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>-0.116235</td>\n",
       "      <td>0.992619</td>\n",
       "      <td>-0.055924</td>\n",
       "      <td>0.203703</td>\n",
       "      <td>0.015740</td>\n",
       "      <td>0.233543</td>\n",
       "      <td>0.082991</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           e401k       inc      marr      male       age     fsize    nettfa  \\\n",
       "e401k   1.000000  0.268178  0.080843 -0.027641  0.031526  0.012015  0.143950   \n",
       "inc     0.268178  1.000000  0.362008 -0.069871  0.105638  0.110170  0.376586   \n",
       "marr    0.080843  0.362008  1.000000 -0.363950  0.059047  0.564814  0.075039   \n",
       "male   -0.027641 -0.069871 -0.363950  1.000000 -0.120297 -0.320678 -0.018132   \n",
       "age     0.031526  0.105638  0.059047 -0.120297  1.000000 -0.030536  0.203906   \n",
       "fsize   0.012015  0.110170  0.564814 -0.320678 -0.030536  1.000000 -0.031506   \n",
       "nettfa  0.143950  0.376586  0.075039 -0.018132  0.203906 -0.031506  1.000000   \n",
       "p401k   0.769170  0.270833  0.085636 -0.024949  0.025977  0.014296  0.187392   \n",
       "pira    0.118643  0.364354  0.116925 -0.036361  0.238557 -0.043629  0.345917   \n",
       "incsq   0.206618  0.940161  0.280060 -0.053715  0.097584  0.079570  0.407568   \n",
       "agesq   0.017526  0.087305  0.054500 -0.116235  0.992619 -0.055924  0.203703   \n",
       "\n",
       "           p401k      pira     incsq     agesq  \n",
       "e401k   0.769170  0.118643  0.206618  0.017526  \n",
       "inc     0.270833  0.364354  0.940161  0.087305  \n",
       "marr    0.085636  0.116925  0.280060  0.054500  \n",
       "male   -0.024949 -0.036361 -0.053715 -0.116235  \n",
       "age     0.025977  0.238557  0.097584  0.992619  \n",
       "fsize   0.014296 -0.043629  0.079570 -0.055924  \n",
       "nettfa  0.187392  0.345917  0.407568  0.203703  \n",
       "p401k   1.000000  0.153033  0.222113  0.015740  \n",
       "pira    0.153033  1.000000  0.322805  0.233543  \n",
       "incsq   0.222113  0.322805  1.000000  0.082991  \n",
       "agesq   0.015740  0.233543  0.082991  1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ I think that the household debt and career are going to be helpful to have. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model in order to better predict who to target when advertising IRAs and 401(k)s. Why would this be an unethical decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ Putting race into the model is an unethical decision because it might producesbinaccurate estimates and misleadsconclusions. Moreover, it could be viewed aw generating data for purposes that harm people or communities of color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we reasonably not use? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ When attempting to predicting income, incsq should not be used since it is the result from squaring the income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs (Subject Matter Experts) might have done this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ incsqr and age are variables that have been created through feature engineering. \n",
    "Expert hope that the polynomial features might expose interactions or relationship between each features.\n",
    "This is because income and age may not have straight relations with other variables.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Looking at the data dictionary, one variable description appears to be an error. What is this error, and what do you think the correct value would be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ In the data dictionary, inc and age should be described as income and age respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all modeling tactics we've learned that could be used to solve a regression problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific regression problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__\n",
    "- a multiple linear regression model: This tactic seems appropriate since these variable might have linear relatiionship between each others.\n",
    "- a k-nearest neighbors model: Apart from classification,this tactic can also be used for regression tasks by calculating the average or weighted average of the target values of the nearest neighbors.\n",
    "- a decision tree: It is effective but based on only one tree. This might leads to Overfitting.\n",
    "- a set of bagged decision trees: bagging typically results in improved accuracy over prediction using a single tree.\n",
    "- a random forest: : Random forest leverages an ensemble of decision trees, resulting in highly accurate predictions. By aggregating the outputs of multiple trees, it reduces the risk of overfitting and provides robust results\n",
    "- an Adaboost model: By combining weak classifiers and focusing more on harder-to-classify instances, AdaBoost ensures a high level of prediction precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend setting a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reggression_models = {'linear' : LinearRegression(),\n",
    "         'knn' : KNeighborsRegressor(),\n",
    "         'tree' : DecisionTreeRegressor(min_samples_split=5,min_samples_leaf=20,random_state=42),\n",
    "         'bagging' : BaggingRegressor(n_estimators=100,random_state=42),\n",
    "         'forest' : RandomForestRegressor(min_samples_split=30,random_state=42),\n",
    "         'adaboost' : AdaBoostRegressor(n_estimators=70,learning_rate=0.1,loss='exponential',random_state=42)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['inc','e401k','p401k','pira','incsq'])\n",
    "y = df[['inc']]\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a FUNCTION to score each models\n",
    "def scoring_models(X_train, X_test, y_train, y_test, models):\n",
    "    for name,model in reggression_models.items():\n",
    "        model.fit(X_train, y_train.values.ravel())\n",
    "        score_train = model.score(X_train, y_train)\n",
    "        score_test = model.score(X_test, y_test)\n",
    "        print(f'Model {name} : Train Score is {score_train:.4f} and Test Score is {score_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model linear : Train Score is 0.2926 and Test Score is 0.2772\n",
      "Model knn : Train Score is 0.5262 and Test Score is 0.3086\n",
      "Model tree : Train Score is 0.4817 and Test Score is 0.3486\n",
      "Model bagging : Train Score is 0.8960 and Test Score is 0.3052\n",
      "Model forest : Train Score is 0.5682 and Test Score is 0.3759\n",
      "Model adaboost : Train Score is 0.3542 and Test Score is 0.3225\n"
     ]
    }
   ],
   "source": [
    "scoring_models(X_train_sc, X_test_sc, y_train, y_test, reggression_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ Bootstrapping is random sampling with replacement. Instead of building one model on our original sample, we will now build one model on each $B$ sub-samples of size $n$ from sample with replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ \n",
    "While decision tree make decisions based on only one tree, the bagged decision tree uses bootstrapped populations on multiple trees which is useful when we want to lower the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ While bagged decision trees uses bootstrapped populations and aggregate the results, Random forest adds a layer of complexity by randomly selecting some features in every split of the tree branch. This prevents the trees from being overly reliant on some features all the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ The advantage of Random forests compared to bagged decision tree model is that it is the superior of bagged decision tree model. Random forests tries to avoid the over-reliance on specific features whcich make it generalize better with lower avriance but higher bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a FUNCTION to evaluate each models\n",
    "def evaluating_models(X_train, X_test, y_train, y_test, models):\n",
    "    for name,model in reggression_models.items():\n",
    "        model.fit(X_train, y_train.values.ravel())\n",
    "        pred_train = model.predict(X_train)\n",
    "        pred_test = model.predict(X_test)\n",
    "        rmse_train = root_mean_squared_error(y_train, pred_train)\n",
    "        rmse_test = root_mean_squared_error(y_test, pred_test)\n",
    "        print(f'Model {name} : Training RMSE is {rmse_train:.4f} and Testing RMSE is {rmse_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model linear : Training RMSE is 20.1642 and Testing RMSE is 20.8648\n",
      "Model knn : Training RMSE is 16.5021 and Testing RMSE is 20.4062\n",
      "Model tree : Training RMSE is 17.2588 and Testing RMSE is 19.8079\n",
      "Model bagging : Training RMSE is 7.7328 and Testing RMSE is 20.4566\n",
      "Model forest : Training RMSE is 15.7542 and Testing RMSE is 19.3882\n",
      "Model adaboost : Training RMSE is 19.2659 and Testing RMSE is 20.2003\n"
     ]
    }
   ],
   "source": [
    "evaluating_models(X_train_sc, X_test_sc, y_train, y_test, reggression_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Based on training RMSE and testing RMSE, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ Overfitting is exist if the RMSE on the training set is lower than on the test set. Based on the result, all model are ovrfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ I would pick Adaboost based on the r-squared and Testing RMSE that quit close to Trianing RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ I think that feature engineering and Gridsearch would help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ The disadvantage of using p401k in the model is that p401k is that while we are trying to predict whether or not someone is eligible for a 401k and p401k is a column that mentions whther or not someone is participate a 401k, this would overfit our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all modeling tactics we've learned that could be used to solve a classification problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific classification problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer:__ \n",
    "- logistic regression model : It is simple, interpretable, and effective for binary classification, especially with linearly separable data.\n",
    "- k-nearest neighbors model : It is non-parametric and easy to understandcapturing local data patterns \n",
    "- decision tree : It is intuitive, interpretable and able to capturing non-linear relationships.\n",
    "- set of bagged decision trees : It reduces variance and increases stability by averaging multiple decision trees trained on different data samples.\n",
    "- random forest : It improves accuracy and robustness by combining the predictions of multiple decision trees and reducing overfitting.\n",
    "- Adaboost model: It boosts performance by sequentially focusing on misclassified examples, improving the accuracy of weak classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_models = {'logistic' : LogisticRegression(),\n",
    "         'knn' : KNeighborsClassifier(),\n",
    "         'tree' : DecisionTreeClassifier(min_samples_split=5,min_samples_leaf=5,random_state=42),\n",
    "         'bagging' : BaggingClassifier(n_estimators=20,random_state=42),\n",
    "         'forest' : RandomForestClassifier(min_samples_split=5,random_state=42),\n",
    "         'adaboost' : AdaBoostClassifier(random_state=42)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['e401k','p401k'])\n",
    "y = df[['e401k']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,test_size=0.20, random_state=42)\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "__Answer:__ \n",
    "- False Positive is when we predict that this person would be eligible for a 401 but in reality that person is not.\n",
    "- False Negative is when we predict that this person would not be eligible for a 401 but in reality that person is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "__Answer:__ In this specific case, I would rather minimize False Negative. The objective of this plan is to promote a tax-advantaged retirement savings. Then, people with false negative  will loss a opportunity to invest and gain earnings which is against the goal of 401k plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "__Answer:__ To minimize False Negative, we would optimize recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "__Answer:__  The F1 score combines precision and recall into a single number that tells us how well a model is performing overall. It finds a balanced middle ground between precision (how accurate our positive predictions are) and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a FUNCTION to accuracy score each models\n",
    "def accuracy_scoring_models(X_train, X_test, y_train, y_test, models):\n",
    "    for name,model in classification_models.items():\n",
    "        model.fit(X_train, y_train.values.ravel())\n",
    "        pred_train = model.predict(X_train)\n",
    "        pred_test = model.predict(X_test)\n",
    "        accuracy_train = accuracy_score(y_train['e401k'], pred_train)\n",
    "        accuracy_test = accuracy_score(y_test['e401k'], pred_test)\n",
    "        print(f'Model {name} : Training Accuracy Score is {accuracy_train:.4f} and Testing Accuracy Score is {accuracy_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logistic : Training Accuracy Score is 0.6526 and Testing Accuracy Score is 0.6674\n",
      "Model knn : Training Accuracy Score is 0.7547 and Testing Accuracy Score is 0.6356\n",
      "Model tree : Training Accuracy Score is 0.8310 and Testing Accuracy Score is 0.5887\n",
      "Model bagging : Training Accuracy Score is 0.9939 and Testing Accuracy Score is 0.6501\n",
      "Model forest : Training Accuracy Score is 0.9869 and Testing Accuracy Score is 0.6593\n",
      "Model adaboost : Training Accuracy Score is 0.6854 and Testing Accuracy Score is 0.6879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "accuracy_scoring_models(X_train_sc, X_test_sc, y_train, y_test, classification_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a FUNCTION to F1_scoring each models\n",
    "def f1_scoring_models(X_train, X_test, y_train, y_test, models):\n",
    "    for name,model in classification_models.items():\n",
    "        model.fit(X_train, y_train.values.ravel())\n",
    "        pred_test = model.predict(X_test)\n",
    "        f1_test = f1_score(y_test['e401k'], pred_test)\n",
    "        print(f'Model {name} : Testing F1-Score is {f1_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logistic : Testing F1-Score is 0.4854\n",
      "Model knn : Testing F1-Score is 0.4894\n",
      "Model tree : Testing F1-Score is 0.4984\n",
      "Model bagging : Testing F1-Score is 0.5348\n",
      "Model forest : Testing F1-Score is 0.5447\n",
      "Model adaboost : Testing F1-Score is 0.5965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "f1_scoring_models(X_train_sc, X_test_sc, y_train, y_test, classification_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "__Answer:__  There are evidence of overfitting in Logistic Regression and AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "__Answer:__ AdaBoost seems to have the strongest performance amoungst all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "__Answer:__  Same as the regression model, I think that feature engineering and Gridsearch would help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Answer the problem.\n",
    "\n",
    "##### BONUS: Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "__Answer:__ \n",
    "For the Regression model, Adaboost is the best model based on the r-squared and Testing RMSE that quit close to Trianing RMSE. On the other hand, AdaBoost seems to have the strongest performance to predict whether or not one is eligible for a 401k amount all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
